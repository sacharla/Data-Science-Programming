{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0tyra0NWJvI"
   },
   "source": [
    "## MNIST machine learning exercise\n",
    "\n",
    "In this exercise we will compare the performance of three different modeling approaches at predicting handwritten numbers. \n",
    "\n",
    "We use the MNIST data set;\n",
    "\n",
    "![mnist data](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmAFVhDJXFBb"
   },
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "48VnFR9cXFP0"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YI7yVb-VW2zi"
   },
   "source": [
    "## Load data and explore/get to know the data structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST digits dataset. It's originally from UCI machine learning library, but included in SKLearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "M8CjaVlYW2Jx",
    "outputId": "e90a4dd3-3781-477f-b02f-97ac3e75be91"
   },
   "outputs": [],
   "source": [
    "mnist = datasets.load_digits() # sklearn includes this data set .. https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dataset is stored in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "5pPXrazAfUoL",
    "outputId": "593b0df0-7b98-4c9b-e01d-36930d653723"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are 1797 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rTQ7qNp4ffaW",
    "outputId": "3d267533-ac01-4747-abee-369aae5d3d79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n"
     ]
    }
   ],
   "source": [
    "print(len(mnist.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are 8x8 grid of values epresenting the gray level for each pixel (16 levels of grey -- from 0 (black) to 15 (white)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "B0ZaSvLlfva0",
    "outputId": "7735e16a-6f2e-41cd-e4e3-55c1dbd5a89d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze this, we simple turn this into a one dimensional array (so we will x1, x2, ... x63, x64). This has already been done for us, and is stored in the data key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "sjDP19CWfT6S",
    "outputId": "f3643de4-6fc9-4810-d5d5-21fb633970fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "Pi5Fvsd_dry5",
    "outputId": "d61e56b6-99c4-486c-b4fa-523f3cb7f1d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(mnist.target[0])\n",
    "print(mnist.target[1])\n",
    "print(mnist.target[2])\n",
    "print(mnist.target[3])\n",
    "print(mnist.target[4])\n",
    "print(mnist.target[5])\n",
    "print(mnist.target[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use matplotlib to display a sample of these images from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qW162_28WC60",
    "outputId": "c7bf771d-ebd1-4a42-e9e4-719d243b814a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in np.random.choice(range(0,len(mnist.images)), 4): # choose 4 at random\n",
    "  plt.imshow(mnist.images[i], cmap='gray')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5WfGTWb3hYd-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.42 s\n",
      "Wall time: 3.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=200)\n",
    "_ = ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 20.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       1.00      1.00      1.00        35\n",
      "           2       0.97      1.00      0.99        36\n",
      "           3       0.95      0.98      0.96        41\n",
      "           4       0.95      0.97      0.96        38\n",
      "           5       0.97      0.97      0.97        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       0.97      0.95      0.96        37\n",
      "           8       0.96      0.93      0.95        29\n",
      "           9       0.94      0.97      0.96        34\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The best accuracy score is 0.9805144212156407\n",
      "... with parameters: {'solver': 'adam', 'max_iter': 5000, 'learning_rate_init': 0.001, 'learning_rate': 'constant', 'hidden_layer_sizes': (70,), 'alpha': 0.5, 'activation': 'tanh'}\n",
      "CPU times: total: 19.2 s\n",
      "Wall time: 8min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.97      1.00      0.99        35\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       0.98      1.00      0.99        41\n",
      "           4       1.00      1.00      1.00        38\n",
      "           5       0.93      0.93      0.93        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       1.00      0.97      0.99        37\n",
      "           8       1.00      0.93      0.96        29\n",
      "           9       0.94      0.97      0.96        34\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "The best accuracy score is 0.9812161246612467\n",
      "... with parameters: {'activation': 'relu', 'alpha': 1, 'hidden_layer_sizes': (90,), 'learning_rate': 'constant', 'learning_rate_init': 0.005, 'max_iter': 5000, 'solver': 'adam'}\n",
      "CPU times: total: 14 s\n",
      "Wall time: 13min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,), (90,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['constant', 'adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.001, 0.005, 0.01, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.97      1.00      0.99        35\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       1.00      0.98      0.99        41\n",
      "           4       0.97      1.00      0.99        38\n",
      "           5       0.94      0.97      0.95        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       1.00      0.97      0.99        37\n",
      "           8       0.97      0.97      0.97        29\n",
      "           9       0.97      0.97      0.97        34\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 17.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a SVM classification model using Random Search for Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 7 is smaller than n_iter=500. Running 7 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "The best accuracy score is 0.9812161246612467\n",
      "... with parameters: {'kernel': 'linear', 'C': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "     'C': [0.0001, 0.001, 0.1, 1, 10, 100, 1000], \n",
    "    'kernel': ['linear']\n",
    "}\n",
    "\n",
    "rand_linear_SVC = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = rand_linear_SVC, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        43\n",
      "           1       0.94      0.91      0.93        35\n",
      "           2       0.84      0.89      0.86        36\n",
      "           3       0.94      0.76      0.84        41\n",
      "           4       0.80      0.95      0.87        38\n",
      "           5       0.83      0.97      0.89        30\n",
      "           6       1.00      0.97      0.99        37\n",
      "           7       0.97      0.81      0.88        37\n",
      "           8       1.00      0.79      0.88        29\n",
      "           9       0.75      0.88      0.81        34\n",
      "\n",
      "    accuracy                           0.89       360\n",
      "   macro avg       0.90      0.89      0.89       360\n",
      "weighted avg       0.90      0.89      0.89       360\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 7.63 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a SVM classification model using Grid Search for Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "The best accuracy score is 0.9812161246612467\n",
      "... with parameters: {'C': 0.001, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "     'C': [0.0001, 0.001, 0.1, 1, 10, 100, 1000], \n",
    "    'kernel': ['linear']\n",
    "}\n",
    "\n",
    "Grid_Linear_SVC = SVC()\n",
    "grid_search = GridSearchCV(estimator = Grid_Linear_SVC, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        43\n",
      "           1       0.94      0.91      0.93        35\n",
      "           2       0.84      0.89      0.86        36\n",
      "           3       0.94      0.76      0.84        41\n",
      "           4       0.80      0.95      0.87        38\n",
      "           5       0.83      0.97      0.89        30\n",
      "           6       1.00      0.97      0.99        37\n",
      "           7       0.97      0.81      0.88        37\n",
      "           8       1.00      0.79      0.88        29\n",
      "           9       0.75      0.88      0.81        34\n",
      "\n",
      "    accuracy                           0.89       360\n",
      "   macro avg       0.90      0.89      0.89       360\n",
      "weighted avg       0.90      0.89      0.89       360\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a SVM classification model using Random Search for Poly kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=500. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n",
      "The best accuracy score is 0.9895687645687646\n",
      "... with parameters: {'kernel': 'poly', 'gamma': 1, 'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 10\n",
    "\n",
    "param_grid = {\n",
    "     'C': [0.1,1, 10, 100], \n",
    "    'gamma': [1,0.1,0.01,0.001],\n",
    "    'kernel': ['poly']\n",
    "}\n",
    "\n",
    "Random_Poly_SVC = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = Random_Poly_SVC, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        43\n",
      "           1       0.94      0.91      0.93        35\n",
      "           2       0.84      0.89      0.86        36\n",
      "           3       0.94      0.76      0.84        41\n",
      "           4       0.80      0.95      0.87        38\n",
      "           5       0.83      0.97      0.89        30\n",
      "           6       1.00      0.97      0.99        37\n",
      "           7       0.97      0.81      0.88        37\n",
      "           8       1.00      0.79      0.88        29\n",
      "           9       0.75      0.88      0.81        34\n",
      "\n",
      "    accuracy                           0.89       360\n",
      "   macro avg       0.90      0.89      0.89       360\n",
      "weighted avg       0.90      0.89      0.89       360\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 14.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a SVM classification model using Grid Search for Poly kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "The best accuracy score is 0.987485481997677\n",
      "... with parameters: {'C': 0.1, 'gamma': 1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "     'C': [0.1,1, 10, 100], \n",
    "    'gamma': [1,0.1,0.01,0.001],\n",
    "    'kernel': ['poly']\n",
    "}\n",
    "\n",
    "\n",
    "Grid_Poly_SVC = SVC()\n",
    "grid_search = GridSearchCV(estimator = Grid_Poly_SVC, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        43\n",
      "           1       0.94      0.91      0.93        35\n",
      "           2       0.84      0.89      0.86        36\n",
      "           3       0.94      0.76      0.84        41\n",
      "           4       0.80      0.95      0.87        38\n",
      "           5       0.83      0.97      0.89        30\n",
      "           6       1.00      0.97      0.99        37\n",
      "           7       0.97      0.81      0.88        37\n",
      "           8       1.00      0.79      0.88        29\n",
      "           9       0.75      0.88      0.81        34\n",
      "\n",
      "    accuracy                           0.89       360\n",
      "   macro avg       0.90      0.89      0.89       360\n",
      "weighted avg       0.90      0.89      0.89       360\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 13.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a SVM classification model using Random Search for RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 9 is smaller than n_iter=500. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "The best accuracy score is 0.751544289044289\n",
      "... with parameters: {'kernel': 'rbf', 'gamma': 0.011, 'C': 10}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 10\n",
    "\n",
    "param_grid = {\n",
    "     'C': [0.1,1, 10], \n",
    "    'gamma': [1,0.1,0.011],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "Random_rbf_SVC = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = Random_rbf_SVC, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        43\n",
      "           1       0.94      0.91      0.93        35\n",
      "           2       0.84      0.89      0.86        36\n",
      "           3       0.94      0.76      0.84        41\n",
      "           4       0.80      0.95      0.87        38\n",
      "           5       0.83      0.97      0.89        30\n",
      "           6       1.00      0.97      0.99        37\n",
      "           7       0.97      0.81      0.88        37\n",
      "           8       1.00      0.79      0.88        29\n",
      "           9       0.75      0.88      0.81        34\n",
      "\n",
      "    accuracy                           0.89       360\n",
      "   macro avg       0.90      0.89      0.89       360\n",
      "weighted avg       0.90      0.89      0.89       360\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 10 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a SVM classification model using Grid Search for rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best accuracy score is 0.8392736159504451\n",
      "... with parameters: {'min_samples_split': 3, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0021, 'max_leaf_nodes': 72, 'max_depth': 11, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "25 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.71399293 0.78983982 0.41963318 0.1892712  0.64716899 0.64791183\n",
      " 0.61171603 0.74321283        nan 0.69653746 0.75500629 0.72230691\n",
      " 0.6075663  0.69723432 0.74117063 0.63748548 0.70768244 0.73973335\n",
      " 0.7236958  0.68688057 0.71607627 0.67844319 0.41963318 0.70768244\n",
      " 0.65897455 0.73901713 0.62144551 0.71399293 0.75716221 0.79888211\n",
      " 0.72650987 0.1892712  0.75154133 0.75083479 0.69375    0.67495403\n",
      " 0.34239015 0.43562476 0.71815476 0.69035763 0.7390631  0.46557298\n",
      " 0.67773422 0.50038473 0.69723432 0.7494459  0.7321114  0.77104384\n",
      " 0.61730062 0.71394938 0.68538521 0.64791183 0.71399293 0.63887195\n",
      " 0.63679104 0.71815476 0.71394938 0.66597222 0.63958091 0.71746032\n",
      " 0.74950155 0.74458237 0.65833333 0.67773422 0.76688928 0.54141018\n",
      " 0.74462834 0.73624903 0.40155827 0.74393148 0.62635501 0.7870451\n",
      " 0.69174652 0.80026616 0.65342625 0.75154133 0.7494459  0.69165457\n",
      " 0.41963318 0.70768244 0.31384533 0.73418022 0.72163424 0.61801926\n",
      " 0.76477449 0.34239015 0.19485579 0.66527778 0.70426345 0.57132937\n",
      " 0.77104142 0.6673103  0.34239015 0.75924797 0.71329849 0.78495693\n",
      " 0.75224545 0.69869338 0.65763889 0.74667296 0.79681814 0.72578639\n",
      " 0.69452913        nan 0.7236958  0.65966899 0.1892712  0.34239015\n",
      " 0.69452913 0.71815476 0.69869338 0.61801926 0.75085414 0.64791183\n",
      " 0.72648326 0.71816202 0.64716899 0.61730062 0.67773422 0.71814992\n",
      " 0.75014034 0.1892712  0.6625     0.68688057 0.68469077 0.65897455\n",
      " 0.80583866 0.80096545 0.71394938 0.46557298 0.75433846 0.75989886\n",
      " 0.70768244 0.34239015 0.75363434 0.78498597 0.63748548 0.7334519\n",
      " 0.74109804 0.76968157 0.82256098 0.70287698 0.72860288 0.75368757\n",
      " 0.1892712  0.7236958  0.71538182 0.60617741 0.71673684 0.72931185\n",
      " 0.30827284 0.78775165 0.72230691 0.72651955 0.78426249 0.65133566\n",
      " 0.75223819 0.62635501 0.51915408 0.69165457 0.78428426 0.70704123\n",
      " 0.75156794 0.65833333 0.5254186  0.73413908 0.66527778 0.68052168\n",
      " 0.7236958  0.54699477 0.69723432 0.66527778 0.66527778 0.72512098\n",
      " 0.72650987 0.70420296 0.83090641 0.66939363 0.72648326 0.65069928\n",
      " 0.34239015 0.54141018 0.71394938 0.65278262 0.6722561  0.63675232\n",
      " 0.63678862 0.66667877 0.71885405 0.60617741 0.72578639 0.70768244\n",
      " 0.72230691 0.66667877 0.71329849 0.78843157 0.69521874 0.67703736\n",
      " 0.65897455 0.67712931 0.75226965 0.49204172 0.62635501 0.72439266\n",
      " 0.74667538 0.66939363 0.76620451 0.71329849 0.7494459  0.7473795\n",
      " 0.72648326 0.7236958  0.77245935 0.69869338 0.74742547 0.69452913\n",
      " 0.70768244 0.19485579 0.65138405 0.77871661 0.62144551 0.5254186\n",
      " 0.65897455 0.73761372 0.66597222 0.71394938 0.70566444 0.78636034\n",
      " 0.74741822 0.65069928 0.69165457 0.65133566 0.71747726        nan\n",
      " 0.69165457 0.63748548 0.74320074 0.77800039 0.68966318 0.68199042\n",
      " 0.76131678 0.61241289 0.53029423 0.67495403 0.72648326 0.61865079\n",
      " 0.70774535 0.63119435 0.57622435 0.65069928 0.64790941 0.63675232\n",
      " 0.66597222 0.72581301 0.65133566        nan 0.71816202 0.80168409\n",
      " 0.64791183 0.75154133 0.61730062 0.7438855  0.65833333 0.70287698\n",
      " 0.61451316 0.76338076 0.71746032 0.71394938 0.63605788 0.19485579\n",
      " 0.65278262 0.79610192 0.66661585 0.77800281 0.75294473 0.8072469\n",
      " 0.76480836 0.70287698 0.72789876 0.61941057 0.75500629 0.80238095\n",
      " 0.72931185 0.7243975  0.71745548 0.61869919 0.72650987 0.68688057\n",
      " 0.78150648 0.70768244 0.71394938 0.77106562 0.70079365 0.69035763\n",
      " 0.28461576 0.66597222 0.67495403 0.72514518 0.71678765 0.53029423\n",
      " 0.70768244 0.65133566 0.79122871 0.78220335 0.75993757 0.72303039\n",
      " 0.65833333 0.44886276 0.63678862 0.72094948 0.67773422 0.79541957\n",
      " 0.70420296 0.72648326 0.71329849 0.64790941 0.70079365 0.28461576\n",
      " 0.73418264 0.60268583 0.69723432 0.52612273 0.7236958  0.72373693\n",
      " 0.74667296 0.75640002 0.71611014 0.70287698 0.67505323 0.60617741\n",
      " 0.82045103 0.71677555 0.7578494  0.65833333 0.34239015 0.72163424\n",
      " 0.71746032 0.6722561  0.63887195 0.7236958  0.70287698 0.78498597\n",
      " 0.76132888 0.72512098 0.62423297 0.51220722 0.79053184 0.67505323\n",
      " 0.67495403 0.31384533 0.63748548 0.72512098 0.72163424 0.72094948\n",
      " 0.51984853 0.74393148 0.6075663  0.74672135 0.78566105 0.59293699\n",
      " 0.75855594 0.68469077 0.70079365 0.80096545 0.61730062 0.54280391\n",
      " 0.64716899 0.7571235  0.79263211 0.68538521        nan 0.66597222\n",
      " 0.72373693 0.71399293 0.75712592 0.64791183 0.6625     0.62635501\n",
      " 0.30060734 0.62635501 0.72163424 0.77662602 0.52750919 0.67703736\n",
      " 0.67495403 0.72932395 0.62144551 0.46557298 0.71676103 0.68538521\n",
      " 0.67844319 0.6625     0.70768244 0.64791183 0.70426345 0.68052168\n",
      " 0.62635501 0.75226965 0.73624903 0.69723432 0.7473674  0.68966318\n",
      " 0.41963318 0.57274245 0.65208817 0.6749637  0.60753484 0.65278262\n",
      " 0.63675232 0.71816202 0.77663811 0.1892712  0.69521874 0.62423297\n",
      " 0.70768244 0.75993757 0.72024777 0.7508856  0.80794861 0.34239015\n",
      " 0.31384533 0.77729142 0.63887195 0.65763889 0.63958091 0.78704994\n",
      " 0.66597222 0.63675232 0.69593254 0.68966318 0.71673684 0.82743419\n",
      " 0.65278262 0.75432878 0.78219125 0.61941057 0.71814992 0.65966899\n",
      " 0.67844319 0.73275261 0.69375    0.72442654 0.70426345 0.83927362\n",
      " 0.77942073 0.57622435 0.77176007 0.76758614 0.71746032 0.74950155\n",
      " 0.72373693 0.69379113 0.19485579 0.6075663  0.74184572 0.69521874\n",
      " 0.72787698 0.66597222 0.72860288 0.76617305 0.79052458 0.7543433\n",
      " 0.70566444 0.75506678 0.6625     0.75431185 0.73138308 0.72373693\n",
      " 0.70356901 0.75641454 0.62423297 0.7473674  0.61941057 0.68538521\n",
      " 0.74249903 0.61801926 0.72163424 0.76202091 0.65138405 0.76063202\n",
      " 0.69171748 0.76058846 0.74736982 0.6165965  0.7967891  0.44886276\n",
      " 0.65625    0.75020567 0.68199042 0.57622435 0.5866265  0.76968157\n",
      " 0.71677555 0.72230691 0.7236958  0.57274245 0.72230691 0.70287698\n",
      " 0.77869241 0.61801926]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.7722726  0.8432485  0.43510788 0.19728702 0.66283649 0.67953366\n",
      " 0.63238884 0.80376252        nan 0.72443001 0.80167072 0.74704265\n",
      " 0.64421251 0.72529973 0.7994106  0.66822326 0.73434457 0.79297128\n",
      " 0.74895735 0.72842487 0.76844606 0.69103099 0.43510788 0.73434457\n",
      " 0.67171378 0.77853105 0.63169062 0.7722726  0.82063617 0.85246831\n",
      " 0.75852575 0.19728702 0.78427426 0.79436213 0.72321232 0.69451077\n",
      " 0.35716563 0.45424573 0.77679797 0.73538517 0.80341529 0.48869081\n",
      " 0.69990313 0.52017406 0.72529973 0.79645015 0.77313914 0.82706944\n",
      " 0.64456624 0.73991085 0.70825338 0.67988164 0.7722726  0.66874575\n",
      " 0.67048549 0.77679797 0.73991085 0.70076709 0.67222553 0.77801582\n",
      " 0.81019927 0.77992508 0.68858425 0.69868574 0.82881235 0.55688637\n",
      " 0.81054664 0.76792144 0.41857857 0.80410943 0.6614352  0.84881735\n",
      " 0.73434003 0.8634324  0.67988497 0.78427426 0.79645015 0.72129867\n",
      " 0.43510788 0.73434457 0.31524002 0.79558603 0.77853831 0.65516903\n",
      " 0.81663269 0.35716563 0.19485072 0.69989677 0.76548802 0.58141477\n",
      " 0.83159587 0.67849987 0.35716563 0.82829076 0.77279479 0.83785734\n",
      " 0.80619503 0.75452545 0.68684361 0.77975192 0.86151845 0.75052303\n",
      " 0.75209006        nan 0.74895735 0.67449881 0.19728702 0.35716563\n",
      " 0.75209006 0.77679797 0.75452545 0.65412555 0.80132001 0.67953366\n",
      " 0.75400235 0.78253831 0.66283649 0.64456624 0.69868574 0.75556862\n",
      " 0.79279631 0.19728702 0.69815613 0.72842487 0.70877542 0.67171378\n",
      " 0.87526106 0.86725773 0.73991085 0.48869081 0.8065424  0.8082832\n",
      " 0.73434457 0.35716563 0.80010625 0.84360071 0.66822326 0.7828813\n",
      " 0.78166421 0.82550664 0.90535861 0.75643879 0.78949665 0.8166342\n",
      " 0.19728702 0.75139289 0.76931608 0.64125478 0.7425203  0.79123487\n",
      " 0.3091514  0.84220502 0.74704265 0.78862936 0.83455178 0.66927461\n",
      " 0.80114822 0.6614352  0.53235797 0.72129867 0.84916623 0.76444364\n",
      " 0.81436985 0.68858425 0.54470958 0.76339698 0.69989677 0.70390389\n",
      " 0.75139289 0.56105846 0.72529973 0.69989677 0.69989677 0.764267\n",
      " 0.75835184 0.73260484 0.91788338 0.68720309 0.75348046 0.67849018\n",
      " 0.35716563 0.55688637 0.73991085 0.67988224 0.70563757 0.65604798\n",
      " 0.66839717 0.70268014 0.77627578 0.64125478 0.75052303 0.73434457\n",
      " 0.74704265 0.70268014 0.77279479 0.84707822 0.74252106 0.70181693\n",
      " 0.67171378 0.71328974 0.80915458 0.51356083 0.6614352  0.7534803\n",
      " 0.79210308 0.68720309 0.83733651 0.77279479 0.79697188 0.79627472\n",
      " 0.75400235 0.75139289 0.84516775 0.75452545 0.80323835 0.75209006\n",
      " 0.73434457 0.19485072 0.6849295  0.84446997 0.63169062 0.54470958\n",
      " 0.67171378 0.78166421 0.70094116 0.73991085 0.76131154 0.84498853\n",
      " 0.81263465 0.67849018 0.72129867 0.66927461 0.76340001        nan\n",
      " 0.72129867 0.66822326 0.78601097 0.82950498 0.73468907 0.71572695\n",
      " 0.81663465 0.63291058 0.54314451 0.6943367  0.75348046 0.64352443\n",
      " 0.7595715  0.65378545 0.60611708 0.67849018 0.67709751 0.65552579\n",
      " 0.70076709 0.76148227 0.66892663        nan 0.78253831 0.86865161\n",
      " 0.67953366 0.78427426 0.64456624 0.78253453 0.68858425 0.75643879\n",
      " 0.64213176 0.8237666  0.77801582 0.73991085 0.65483104 0.19485072\n",
      " 0.67988224 0.84846755 0.67571484 0.82428425 0.80375495 0.87735013\n",
      " 0.82202793 0.75643879 0.76444106 0.65569107 0.80167072 0.86865161\n",
      " 0.79123487 0.75104386 0.75522049 0.64177924 0.75835184 0.72842487\n",
      " 0.85212533 0.73434457 0.73991085 0.84516775 0.75730912 0.73538517\n",
      " 0.28462043 0.70076709 0.69451077 0.7907095  0.76966284 0.54314451\n",
      " 0.73434457 0.66927461 0.84724986 0.85543043 0.8133291  0.78253937\n",
      " 0.68858425 0.46572748 0.66839717 0.78601673 0.69868574 0.86534696\n",
      " 0.73260484 0.75382843 0.77279479 0.67709751 0.75730912 0.28462043\n",
      " 0.79402187 0.63238597 0.72495175 0.53983835 0.75139289 0.78793022\n",
      " 0.77975192 0.80167072 0.75330215 0.75643879 0.70371923 0.64125478\n",
      " 0.90066008 0.76705415 0.82550694 0.68858425 0.35716563 0.75643819\n",
      " 0.77801582 0.70563757 0.66874575 0.74895735 0.75643879 0.84360071\n",
      " 0.82220229 0.764267   0.63290801 0.52504772 0.85612215 0.70371923\n",
      " 0.69451077 0.31524002 0.66822326 0.764267   0.75643819 0.78601673\n",
      " 0.53305422 0.80550271 0.64421251 0.81263465 0.83594309 0.62438521\n",
      " 0.82602808 0.70877542 0.75730912 0.86517077 0.64439217 0.57115299\n",
      " 0.66283649 0.80445393 0.86534272 0.70999311        nan 0.70094116\n",
      " 0.78793022 0.7722726  0.80880009 0.67988164 0.69815613 0.6614352\n",
      " 0.30375828 0.6614352  0.75643819 0.83681568 0.54679653 0.70094661\n",
      " 0.6943367  0.76983479 0.63169062 0.48869081 0.7546983  0.70999311\n",
      " 0.69103099 0.69815613 0.73434457 0.67988164 0.76548802 0.70390389\n",
      " 0.6614352  0.80915458 0.76792144 0.72529973 0.79158103 0.73468907\n",
      " 0.43510788 0.59481515 0.6776194  0.68929156 0.63117145 0.67988224\n",
      " 0.65604798 0.78271238 0.84446891 0.19728702 0.74252106 0.63290801\n",
      " 0.73434457 0.8133291  0.78410641 0.81628804 0.88117728 0.35716563\n",
      " 0.31524002 0.82846301 0.66874575 0.68684361 0.67222553 0.83594309\n",
      " 0.70076709 0.65604798 0.72911825 0.73468907 0.7425203  0.91388307\n",
      " 0.67796753 0.80428108 0.84777538 0.65569107 0.75556862 0.67449881\n",
      " 0.69103099 0.77870572 0.72321232 0.7585259  0.76548802 0.94032739\n",
      " 0.8505595  0.60611708 0.84133787 0.82446483 0.77801582 0.8126345\n",
      " 0.78793022 0.71415991 0.19485072 0.64369077 0.80289386 0.74252106\n",
      " 0.75348061 0.70076709 0.78949665 0.82271858 0.85542907 0.81332743\n",
      " 0.76131154 0.82359541 0.69815613 0.79958194 0.7931511  0.78793022\n",
      " 0.76357332 0.81280418 0.63290801 0.78322958 0.65569107 0.70825338\n",
      " 0.7783591  0.65516903 0.75643819 0.8209843  0.6849295  0.81698354\n",
      " 0.72198903 0.80602142 0.78218716 0.64195785 0.85838604 0.46572748\n",
      " 0.68614735 0.81576554 0.71572695 0.60611708 0.60298695 0.82550664\n",
      " 0.76757589 0.74704265 0.74895735 0.59481515 0.74704265 0.75643879\n",
      " 0.82272191 0.65412555]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,100),  \n",
    "    'min_samples_leaf': np.arange(1,100),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 100), \n",
    "    'max_depth': np.arange(1,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        43\n",
      "           1       0.91      0.91      0.91        35\n",
      "           2       0.87      0.92      0.89        36\n",
      "           3       0.78      0.85      0.81        41\n",
      "           4       0.92      0.95      0.94        38\n",
      "           5       0.79      0.87      0.83        30\n",
      "           6       1.00      0.97      0.99        37\n",
      "           7       0.97      0.81      0.88        37\n",
      "           8       1.00      0.76      0.86        29\n",
      "           9       0.81      0.88      0.85        34\n",
      "\n",
      "    accuracy                           0.89       360\n",
      "   macro avg       0.90      0.89      0.89       360\n",
      "weighted avg       0.90      0.89      0.89       360\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 6.03 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference:\n",
    "\n",
    "If we are to predict based on the accuracy alone, we see that the accuracy is more for the Poly Kernel under SVM. But if we are to predict based on the f1 score which tends to be a better metric for uneven data, we see an avg f1 score for the Neural Networks when I consider tuning the parameters for the Grid search with exhausting searching is 98% which is better than any other model. The SVM tends to average with its performance metrics at the overall 89%. This is because the SVM works best with the smaller number of features which are already distinct in nature. Where as the Neural Networks tend to be more adaptive for the classification and image recognition. It can work and learn from the multi layered dimensions and can also classify them into their respective distinct groups which the SVM can't. Hence it is generally more feasible to use this kind of a model over the SVM for such problems."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOig4eSm144+FaPk1GKk187",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "mnist_compete_3_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b056086e24cb5602cbcb82122035cd3d6ee2ccbf5df29c16e348c108b0f83be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
