{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3b45d43-1b16-43da-a953-9978085dc99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4453780-466b-4504-89a9-b2e39ac6cb31",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7780dfa-76db-4200-bbf8-9f7a24275842",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('C:/Users/Srinidhi/Documents/USF/Data_Science_Programming/Week4_Assignments/airbnb_train_X_price_gte_150.csv') \n",
    "y_train = pd.read_csv('C:/Users/Srinidhi/Documents/USF/Data_Science_Programming/Week4_Assignments/airbnb_train_y_price_gte_150.csv') \n",
    "X_test = pd.read_csv('C:/Users/Srinidhi/Documents/USF/Data_Science_Programming/Week4_Assignments/airbnb_test_X_price_gte_150.csv') \n",
    "y_test = pd.read_csv('C:/Users/Srinidhi/Documents/USF/Data_Science_Programming/Week4_Assignments/airbnb_test_y_price_gte_150.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "340b658f-8054-49f5-84b4-5169051271fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>...</th>\n",
       "      <th>property_type_Condominium</th>\n",
       "      <th>property_type_Dorm</th>\n",
       "      <th>property_type_Entire Floor</th>\n",
       "      <th>property_type_Guesthouse</th>\n",
       "      <th>property_type_House</th>\n",
       "      <th>property_type_Loft</th>\n",
       "      <th>property_type_Other</th>\n",
       "      <th>property_type_Townhouse</th>\n",
       "      <th>property_type_Villa</th>\n",
       "      <th>property_type_unkown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.884939</td>\n",
       "      <td>1.012890</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539411</td>\n",
       "      <td>-0.441906</td>\n",
       "      <td>0.999675</td>\n",
       "      <td>0.375655</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.808025</td>\n",
       "      <td>0.861706</td>\n",
       "      <td>0</td>\n",
       "      <td>0.539411</td>\n",
       "      <td>-0.441906</td>\n",
       "      <td>2.325470</td>\n",
       "      <td>1.333267</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.215255</td>\n",
       "      <td>-0.095632</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.017689</td>\n",
       "      <td>-0.441906</td>\n",
       "      <td>-0.326120</td>\n",
       "      <td>0.375655</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.857605</td>\n",
       "      <td>-1.058074</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.574789</td>\n",
       "      <td>-0.441906</td>\n",
       "      <td>-0.326120</td>\n",
       "      <td>-0.581957</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.199298</td>\n",
       "      <td>1.125934</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.574789</td>\n",
       "      <td>-0.441906</td>\n",
       "      <td>-0.326120</td>\n",
       "      <td>-0.581957</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.482015</td>\n",
       "      <td>0.675233</td>\n",
       "      <td>1</td>\n",
       "      <td>0.539411</td>\n",
       "      <td>0.564007</td>\n",
       "      <td>-0.326120</td>\n",
       "      <td>-0.581957</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.023296</td>\n",
       "      <td>0.126650</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.131889</td>\n",
       "      <td>-0.441906</td>\n",
       "      <td>-0.326120</td>\n",
       "      <td>-0.581957</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.177577</td>\n",
       "      <td>0.691157</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.574789</td>\n",
       "      <td>-0.441906</td>\n",
       "      <td>-0.326120</td>\n",
       "      <td>-0.581957</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.457699</td>\n",
       "      <td>-1.419131</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.131889</td>\n",
       "      <td>0.564007</td>\n",
       "      <td>-0.326120</td>\n",
       "      <td>-0.581957</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.123707</td>\n",
       "      <td>0.262572</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.574789</td>\n",
       "      <td>0.564007</td>\n",
       "      <td>-0.326120</td>\n",
       "      <td>-0.581957</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2488 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      host_is_superhost  host_identity_verified  latitude  longitude  \\\n",
       "0                     0                       0  0.884939   1.012890   \n",
       "1                     0                       1 -1.808025   0.861706   \n",
       "2                     0                       1  0.215255  -0.095632   \n",
       "3                     0                       0 -1.857605  -1.058074   \n",
       "4                     0                       0 -1.199298   1.125934   \n",
       "...                 ...                     ...       ...        ...   \n",
       "2483                  0                       1 -1.482015   0.675233   \n",
       "2484                  0                       1 -0.023296   0.126650   \n",
       "2485                  0                       1  0.177577   0.691157   \n",
       "2486                  0                       1 -1.457699  -1.419131   \n",
       "2487                  0                       1 -0.123707   0.262572   \n",
       "\n",
       "      room_type  accommodates  bathrooms  bedrooms      beds  bed_type  ...  \\\n",
       "0             0      0.539411  -0.441906  0.999675  0.375655         4  ...   \n",
       "1             0      0.539411  -0.441906  2.325470  1.333267         4  ...   \n",
       "2             0     -0.017689  -0.441906 -0.326120  0.375655         4  ...   \n",
       "3             1     -0.574789  -0.441906 -0.326120 -0.581957         4  ...   \n",
       "4             0     -0.574789  -0.441906 -0.326120 -0.581957         4  ...   \n",
       "...         ...           ...        ...       ...       ...       ...  ...   \n",
       "2483          1      0.539411   0.564007 -0.326120 -0.581957         4  ...   \n",
       "2484          1     -1.131889  -0.441906 -0.326120 -0.581957         4  ...   \n",
       "2485          0     -0.574789  -0.441906 -0.326120 -0.581957         4  ...   \n",
       "2486          1     -1.131889   0.564007 -0.326120 -0.581957         4  ...   \n",
       "2487          1     -0.574789   0.564007 -0.326120 -0.581957         4  ...   \n",
       "\n",
       "      property_type_Condominium  property_type_Dorm  \\\n",
       "0                             0                   0   \n",
       "1                             1                   0   \n",
       "2                             0                   0   \n",
       "3                             1                   0   \n",
       "4                             0                   0   \n",
       "...                         ...                 ...   \n",
       "2483                          0                   0   \n",
       "2484                          0                   0   \n",
       "2485                          1                   0   \n",
       "2486                          0                   0   \n",
       "2487                          1                   0   \n",
       "\n",
       "      property_type_Entire Floor  property_type_Guesthouse  \\\n",
       "0                              0                         0   \n",
       "1                              0                         0   \n",
       "2                              0                         0   \n",
       "3                              0                         0   \n",
       "4                              0                         0   \n",
       "...                          ...                       ...   \n",
       "2483                           0                         0   \n",
       "2484                           0                         0   \n",
       "2485                           0                         0   \n",
       "2486                           0                         0   \n",
       "2487                           0                         0   \n",
       "\n",
       "      property_type_House  property_type_Loft  property_type_Other  \\\n",
       "0                       0                   0                    0   \n",
       "1                       0                   0                    0   \n",
       "2                       0                   0                    0   \n",
       "3                       0                   0                    0   \n",
       "4                       1                   0                    0   \n",
       "...                   ...                 ...                  ...   \n",
       "2483                    1                   0                    0   \n",
       "2484                    0                   0                    0   \n",
       "2485                    0                   0                    0   \n",
       "2486                    1                   0                    0   \n",
       "2487                    0                   0                    0   \n",
       "\n",
       "      property_type_Townhouse  property_type_Villa  property_type_unkown  \n",
       "0                           0                    0                     0  \n",
       "1                           0                    0                     0  \n",
       "2                           0                    0                     0  \n",
       "3                           0                    0                     0  \n",
       "4                           0                    0                     0  \n",
       "...                       ...                  ...                   ...  \n",
       "2483                        0                    0                     0  \n",
       "2484                        0                    0                     0  \n",
       "2485                        0                    0                     0  \n",
       "2486                        0                    0                     0  \n",
       "2487                        0                    0                     0  \n",
       "\n",
       "[2488 rows x 55 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329cfabd-4365-4321-8ae6-83d0c37269cc",
   "metadata": {},
   "source": [
    "### Fit a SVM classification model using Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d5dc02d-c88f-471b-96f5-2a17bf3eba0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=500. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best precision score is 0.9082834459352075\n",
      "... with parameters: {'kernel': 'poly', 'gamma': 0.01, 'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 10\n",
    "\n",
    "param_grid = {\n",
    "     'C': [0.1,1, 10, 100], \n",
    "    'gamma': [1,0.1,0.01,0.001],\n",
    "    'kernel': ['poly']\n",
    "}\n",
    "\n",
    "Random_SVC = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = Random_SVC, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2735e14c-712c-487f-85d5-6efd8087d7c1",
   "metadata": {},
   "source": [
    "### Fit a SVM classification model using Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "645d5d60-d99e-4252-963a-85f3ad26fa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best precision score is 0.9082834459352075\n",
      "... with parameters: {'C': 0.1, 'gamma': 0.01, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 10\n",
    "\n",
    "param_grid = {\n",
    "     'C': [0.1,1, 10, 100], \n",
    "     'gamma': [1,0.1,0.01,0.001],\n",
    "    'kernel': ['poly']\n",
    "}\n",
    "\n",
    "Grid_SVC = SVC()\n",
    "grid_search = GridSearchCV(estimator = Grid_SVC, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestPrecisionTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aeffd6-0771-4f78-828f-cf54d1b210ff",
   "metadata": {},
   "source": [
    "## Model the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb85032-8e1e-4352-acb4-fc2ad45cef82",
   "metadata": {},
   "source": [
    "## Initial random search based on the parameters set for the Random search for the Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1f6564c-318e-4997-b2af-b8686076a273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 500 candidates, totalling 5000 fits\n",
      "The best precision score is 0.857258983228262\n",
      "... with parameters: {'min_samples_split': 30, 'min_samples_leaf': 23, 'min_impurity_decrease': 0.0021, 'max_leaf_nodes': 91, 'max_depth': 35, 'criterion': 'gini'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 5000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.77914269 0.77914269 0.84902027 0.84204298 0.8257419         nan\n",
      " 0.83267469 0.82603176 0.8304701  0.83799995 0.8257419  0.83332932\n",
      " 0.82554033        nan 0.8257419  0.8257419  0.82647592 0.84198451\n",
      " 0.8257419  0.8257419  0.8257419  0.8257419  0.83009475 0.82718093\n",
      " 0.82694569 0.84684699 0.83357184 0.8257419  0.8257419  0.8257419\n",
      " 0.8257419  0.8257419  0.77914269 0.8257419  0.8257419  0.8257419\n",
      " 0.82739967 0.8257419  0.84848576 0.8257419  0.82603176 0.8257419\n",
      " 0.82647592 0.8257419  0.8257419  0.8257419  0.83332932 0.82885243\n",
      " 0.82603176 0.84578445 0.82554033 0.8257419  0.8257419  0.82718093\n",
      " 0.8257419  0.8257419  0.84398318 0.8257419  0.83332932 0.83384648\n",
      " 0.8257419  0.8257419  0.8257419  0.8257419  0.83332932 0.82891552\n",
      " 0.8257419  0.8257419  0.8415919  0.82886788 0.8257419  0.82634721\n",
      " 0.8257419  0.84342294 0.8257419  0.8257419  0.82852399 0.8257419\n",
      " 0.82262922 0.8257419  0.8257419  0.8393102  0.82718093 0.8294669\n",
      " 0.82780877 0.8257419  0.85213204 0.8257419  0.8257419  0.82739967\n",
      " 0.82747079 0.8413664  0.8257419  0.82718093 0.8346214  0.82708123\n",
      " 0.8257419  0.8257419  0.8257419  0.83881062 0.82747079 0.8257419\n",
      " 0.8257419  0.83009475 0.8257419  0.82603176 0.8257419  0.83249821\n",
      " 0.8257419  0.8257419  0.8372336  0.83098617 0.84887033 0.8257419\n",
      " 0.8257419  0.8257419  0.8257419  0.8257419  0.8257419  0.8257419\n",
      " 0.8257419  0.83916942 0.82718093 0.84832117 0.83332932 0.84900535\n",
      " 0.8257419  0.8257419  0.8257419         nan 0.8257419  0.8257419\n",
      " 0.8257419  0.83294199 0.83151564 0.81866496 0.8257419  0.83895635\n",
      " 0.8257419  0.8257419  0.83678511 0.8440813  0.84369382 0.83947033\n",
      " 0.8257419  0.8257419  0.8393102  0.8257419  0.84773298 0.8257419\n",
      " 0.8257419  0.8257419  0.8257419  0.84552738 0.8257419  0.83332932\n",
      " 0.8413664  0.8257419         nan 0.8257419  0.8257419  0.8257419\n",
      " 0.82701211 0.8257419  0.8257419  0.8257419  0.82780877 0.82935692\n",
      " 0.77914269 0.8257419  0.8257419  0.8257419  0.83328064 0.8257419\n",
      " 0.82554033 0.8257419  0.82603176 0.83972667 0.82718093 0.8393102\n",
      " 0.83594375 0.8257419  0.83187032 0.8257419  0.8257419  0.8257419\n",
      " 0.8257419  0.8257419  0.83327601 0.83233078 0.83009475 0.8257419\n",
      " 0.84587025 0.83478171 0.8257419  0.83695212 0.77914269 0.8257419\n",
      " 0.82554033 0.8257419  0.8257419  0.8257419  0.8304155  0.8257419\n",
      " 0.83052894 0.8257419  0.8257419  0.83649137 0.84228255 0.8346214\n",
      " 0.8257419  0.8257419  0.8257419  0.8257419  0.83677498 0.8257419\n",
      " 0.83065205 0.82780877 0.82647592 0.84666349 0.8257419  0.8257419\n",
      " 0.84578778 0.83009475 0.82826636 0.84248254 0.83332932 0.8257419\n",
      " 0.8257419  0.8257419  0.8257419  0.83263088 0.8257419  0.8257419\n",
      " 0.77914269 0.8257419  0.8257419  0.84707163 0.82554033 0.8257419\n",
      " 0.8257419  0.83628571 0.83294199 0.8257419  0.8257419  0.8257419\n",
      " 0.8257419  0.83076717 0.8257419  0.82718093 0.8257419  0.8257419\n",
      " 0.82554033 0.77914269 0.8257419  0.84735351 0.84645937 0.8257419\n",
      " 0.84625283 0.82170969 0.8257419  0.8257419  0.82708123 0.8257419\n",
      " 0.83332932 0.8257419  0.8257419  0.84543785 0.8257419  0.84667487\n",
      " 0.8257419  0.8257419  0.8257419  0.8257419  0.83312157 0.8257419\n",
      " 0.83159277 0.8257419  0.85207567 0.83332932 0.84664878 0.8257419\n",
      " 0.82718093 0.82739967 0.83868413 0.83332932 0.8257419  0.8257419\n",
      " 0.84321825 0.8257419  0.84666349 0.8257419  0.8257419  0.8257419\n",
      "        nan 0.83009475 0.84122561 0.83226768 0.8257419  0.84232223\n",
      " 0.77914269 0.8257419  0.8257419  0.8257419  0.8257419  0.82694569\n",
      " 0.84345536 0.8257419  0.8257419  0.77914269 0.83112429 0.84645937\n",
      " 0.8257419  0.8257419  0.82647592 0.84188227 0.8257419  0.82603176\n",
      " 0.8257419  0.83332932 0.8257419  0.82804947 0.84861342 0.8431049\n",
      " 0.83340868 0.8257419  0.8257419  0.8257419  0.82718093 0.83500356\n",
      " 0.83799995 0.84754329 0.8257419  0.8257419  0.83327601 0.8257419\n",
      " 0.8257419  0.8257419  0.82708123 0.84552738 0.8257419  0.82809863\n",
      " 0.8257419  0.84425088 0.8257419  0.83752464 0.83156171 0.83009475\n",
      " 0.8257419  0.77914269 0.8257419  0.8393102  0.8322774  0.84213671\n",
      " 0.8257419  0.8294669  0.8257419  0.8257419  0.8257419  0.83799995\n",
      " 0.84611808 0.8257419  0.8257419  0.83403136 0.8257419  0.8257419\n",
      " 0.8257419  0.8431049  0.83294199 0.77914269 0.8257419  0.8257419\n",
      " 0.8257419  0.82718093 0.8257419  0.83685402 0.84615303 0.8257419\n",
      " 0.77914269 0.84873954 0.8257419  0.84666349 0.83009475 0.82603176\n",
      " 0.8257419  0.84664878 0.83345084 0.8257419  0.8257419  0.82780877\n",
      " 0.82603176 0.84248254 0.8257419  0.8257419  0.8257419  0.8257419\n",
      " 0.83515989 0.8257419  0.8257419  0.8257419  0.8257419  0.8257419\n",
      " 0.84357083 0.77914269 0.82780877 0.8257419  0.85725898 0.82718093\n",
      " 0.8257419  0.8257419  0.83288154 0.8257419  0.8257419  0.8257419\n",
      " 0.8257419  0.8257419  0.84758392 0.8257419  0.82933366 0.8257419\n",
      " 0.8257419  0.8257419  0.84474297 0.84543785 0.8257419  0.8257419\n",
      " 0.83332932 0.77914269 0.8257419  0.8269569  0.8257419  0.8257419\n",
      " 0.83332932 0.83520988 0.83377086 0.8257419  0.82754256 0.8257419\n",
      " 0.83470706 0.83665484 0.8294669  0.8298055  0.8257419  0.8257419\n",
      " 0.8415919  0.82647592 0.84687892 0.8257419  0.83332932 0.82911703\n",
      " 0.83802973 0.84552738 0.8257419  0.84659843 0.77914269 0.83410745\n",
      " 0.8257419  0.83327601 0.8257419  0.84666349 0.82603176 0.82780877\n",
      " 0.8257419  0.8257419  0.8257419  0.84587016 0.8257419  0.84148597\n",
      " 0.83163553 0.83882426 0.84880292 0.8257419  0.82986388 0.8257419\n",
      " 0.8257419  0.8257419  0.84331335 0.77914269 0.8257419  0.8294669\n",
      " 0.82708123 0.8257419  0.8257419  0.83332932 0.8257419  0.8257419\n",
      " 0.82716638 0.8257419  0.8257419  0.83190553 0.84620015 0.85332352\n",
      " 0.83370894 0.8257419  0.82290294 0.83009475 0.82852399 0.83538312\n",
      " 0.8257419  0.83185743]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.77772001 0.77772001 0.85848823 0.84626316 0.8260633         nan\n",
      " 0.85044027 0.82779975 0.84092874 0.84316725 0.8260633  0.83705796\n",
      " 0.82736865        nan 0.8260633  0.8260633  0.82853909 0.85243919\n",
      " 0.8260633  0.8260633  0.8260633  0.8260633  0.83508146 0.83079812\n",
      " 0.83108266 0.85457433 0.83798673 0.8260633  0.8260633  0.8260633\n",
      " 0.8260633  0.8260633  0.77772001 0.8260633  0.8260633  0.8260633\n",
      " 0.83175618 0.8260633  0.86203319 0.8260633  0.82779975 0.8260633\n",
      " 0.82853909 0.8260633  0.8260633  0.8260633  0.83705796 0.84288285\n",
      " 0.82779975 0.8551776  0.82735507 0.8260633  0.8260633  0.83078458\n",
      " 0.8260633  0.8260633  0.84715694 0.8260633  0.83705796 0.84273683\n",
      " 0.8260633  0.8260633  0.8260633  0.8260633  0.83705796 0.83624034\n",
      " 0.8260633  0.8260633  0.84425986 0.8323241  0.8260633  0.82846028\n",
      " 0.8260633  0.84851534 0.8260633  0.8260633  0.83190477 0.8260633\n",
      " 0.83499179 0.8260633  0.8260633  0.84475523 0.83078458 0.83291031\n",
      " 0.83296927 0.8260633  0.87520269 0.8260633  0.8260633  0.83175618\n",
      " 0.83253457 0.84665389 0.8260633  0.83079812 0.84681898 0.83093608\n",
      " 0.8260633  0.8260633  0.8260633  0.84561109 0.83253457 0.8260633\n",
      " 0.8260633  0.83508146 0.8260633  0.82779975 0.8260633  0.83901308\n",
      " 0.8260633  0.8260633  0.86343346 0.8339496  0.85360933 0.8260633\n",
      " 0.8260633  0.8260633  0.8260633  0.8260633  0.8260633  0.8260633\n",
      " 0.8260633  0.84216228 0.83078458 0.85315307 0.83705796 0.86122855\n",
      " 0.8260633  0.8260633  0.8260633         nan 0.8260633  0.8260633\n",
      " 0.8260633  0.83878116 0.83608807 0.83577786 0.8260633  0.84517389\n",
      " 0.8260633  0.8260633  0.8425989  0.84972214 0.85081847 0.85954614\n",
      " 0.8260633  0.8260633  0.84536998 0.8260633  0.86009645 0.8260633\n",
      " 0.8260633  0.8260633  0.8260633  0.84799618 0.8260633  0.83705796\n",
      " 0.84726864 0.8260633         nan 0.8260633  0.8260633  0.8260633\n",
      " 0.8324863  0.8260633  0.8260633  0.8260633  0.83296927 0.84581085\n",
      " 0.77772001 0.8260633  0.8260633  0.8260633  0.84279774 0.8260633\n",
      " 0.82713318 0.8260633  0.82779975 0.85442297 0.83079812 0.84475523\n",
      " 0.84126859 0.8260633  0.83597087 0.8260633  0.8260633  0.8260633\n",
      " 0.8260633  0.8260633  0.83882986 0.83638731 0.83508146 0.8260633\n",
      " 0.85279475 0.84610163 0.8260633  0.84416919 0.77772001 0.8260633\n",
      " 0.82851139 0.8260633  0.8260633  0.8260633  0.83277461 0.8260633\n",
      " 0.83739824 0.8260633  0.8260633  0.84159304 0.84826198 0.84681898\n",
      " 0.8260633  0.8260633  0.8260633  0.8260633  0.85691286 0.8260633\n",
      " 0.83628297 0.83296927 0.82853909 0.85929181 0.8260633  0.8260633\n",
      " 0.86467628 0.83508146 0.84965049 0.84919474 0.83705796 0.8260633\n",
      " 0.8260633  0.8260633  0.8260633  0.83775739 0.8260633  0.8260633\n",
      " 0.77772001 0.8260633  0.8260633  0.85092435 0.8273412  0.8260633\n",
      " 0.8260633  0.84181518 0.83878116 0.8260633  0.8260633  0.8260633\n",
      " 0.8260633  0.8431759  0.8260633  0.83078458 0.8260633  0.8260633\n",
      " 0.82711907 0.77772001 0.8260633  0.85647509 0.85745102 0.8260633\n",
      " 0.85911257 0.8390312  0.8260633  0.8260633  0.83093608 0.8260633\n",
      " 0.83705796 0.8260633  0.8260633  0.84860947 0.8260633  0.86583241\n",
      " 0.8260633  0.8260633  0.8260633  0.8260633  0.83973417 0.8260633\n",
      " 0.83840218 0.8260633  0.85518341 0.83705796 0.85466548 0.8260633\n",
      " 0.83079812 0.83175618 0.8461695  0.83705796 0.8260633  0.8260633\n",
      " 0.84800077 0.8260633  0.8598492  0.8260633  0.8260633  0.8260633\n",
      "        nan 0.83508146 0.84406094 0.84086693 0.8260633  0.84992088\n",
      " 0.77772001 0.8260633  0.8260633  0.8260633  0.8260633  0.83108266\n",
      " 0.848917   0.8260633  0.8260633  0.77772001 0.84091635 0.85759939\n",
      " 0.8260633  0.8260633  0.82853909 0.8619563  0.8260633  0.82779975\n",
      " 0.8260633  0.83705796 0.8260633  0.83105754 0.86341084 0.84589861\n",
      " 0.83867852 0.8260633  0.8260633  0.8260633  0.83079812 0.85554495\n",
      " 0.84316725 0.86360493 0.8260633  0.8260633  0.83882986 0.8260633\n",
      " 0.8260633  0.8260633  0.83102047 0.84799618 0.8260633  0.83470572\n",
      " 0.8260633  0.84933687 0.8260633  0.87598937 0.83602875 0.83508146\n",
      " 0.8260633  0.77772001 0.8260633  0.84475523 0.91929095 0.86132408\n",
      " 0.8260633  0.83291031 0.8260633  0.8260633  0.8260633  0.84316725\n",
      " 0.8584984  0.8260633  0.8260633  0.84066159 0.8260633  0.8260633\n",
      " 0.8260633  0.84589861 0.83878116 0.77772001 0.8260633  0.8260633\n",
      " 0.8260633  0.83079812 0.8260633  0.84120931 0.86306997 0.8260633\n",
      " 0.77772001 0.86342408 0.8260633  0.85935274 0.83508146 0.82779975\n",
      " 0.8260633  0.8541081  0.86540102 0.8260633  0.8260633  0.83296927\n",
      " 0.82779975 0.84919474 0.8260633  0.8260633  0.8260633  0.8260633\n",
      " 0.84242109 0.8260633  0.8260633  0.8260633  0.8260633  0.8260633\n",
      " 0.86296253 0.77772001 0.83296927 0.8260633  0.86585808 0.83079812\n",
      " 0.8260633  0.8260633  0.84928773 0.8260633  0.8260633  0.8260633\n",
      " 0.8260633  0.8260633  0.84985763 0.8260633  0.83664358 0.8260633\n",
      " 0.8260633  0.8260633  0.8689015  0.84860947 0.8260633  0.8260633\n",
      " 0.83705796 0.77772001 0.8260633  0.83362562 0.8260633  0.8260633\n",
      " 0.83705796 0.84286034 0.83812552 0.8260633  0.84216186 0.8260633\n",
      " 0.84767887 0.85376876 0.83291031 0.83881453 0.8260633  0.8260633\n",
      " 0.84425986 0.82853909 0.86346943 0.8260633  0.83705796 0.83682169\n",
      " 0.89068264 0.84799618 0.8260633  0.8531774  0.77772001 0.84535432\n",
      " 0.8260633  0.83882986 0.8260633  0.8598492  0.82779975 0.83296927\n",
      " 0.8260633  0.8260633  0.8260633  0.87029485 0.8260633  0.84954476\n",
      " 0.83863315 0.85146561 0.86523072 0.8260633  0.83193091 0.8260633\n",
      " 0.8260633  0.8260633  0.86315725 0.77772001 0.8260633  0.83291031\n",
      " 0.83092298 0.8260633  0.8260633  0.83705796 0.8260633  0.8260633\n",
      " 0.83081743 0.8260633  0.8260633  0.84192339 0.87868109 0.86891522\n",
      " 0.83678627 0.8260633  0.84822013 0.83508146 0.83190477 0.84100548\n",
      " 0.8260633  0.8393544 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 10\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,100),  \n",
    "    'min_samples_leaf': np.arange(1,100),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 100), \n",
    "    'max_depth': np.arange(1,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cc64f7-3bc9-4c41-9caa-a7d62a2aa730",
   "metadata": {},
   "source": [
    "## Conduct an exhaustive search across a smaller range of parameters around the parameters found in the initial random search and use the grid search for the Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "001eb8f2-3fcc-43d7-90aa-1bb29ae9c033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2048 candidates, totalling 20480 fits\n",
      "The best precision score is 0.8491060849466383\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 33, 'max_leaf_nodes': 89, 'min_impurity_decrease': 0.0023, 'min_samples_leaf': 23, 'min_samples_split': 28}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"precision\"\n",
    "kfolds = 10\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(28,32),  \n",
    "    'min_samples_leaf': np.arange(21,25),\n",
    "    'min_impurity_decrease': np.arange(0.0018, 0.0025, 0.0001),\n",
    "    'max_leaf_nodes': np.arange(89,93), \n",
    "    'max_depth': np.arange(33,37), \n",
    "    'criterion': ['entropy'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6df3a9-08e4-4851-99c5-cdf088b91c34",
   "metadata": {},
   "source": [
    "## Inference:\n",
    "\n",
    "1. I have considered 10 fold cross validation to use random search CV on the SVM classification model with poly kernel and I have received the precision value of 90.8\n",
    "2. I have considered 10 fold cross validation to use grid search CV on the SVM classification model with poly kernel and I have received the precision value of 908\n",
    "3. I have considered 10 fold cross validation to use random search on the Decision tree classification model with poly kernel and I have received the precision value of 85.7\n",
    "4.  I have considered 10 fold cross validation to use grid search on the Decision tree model with poly kernel and I have received the precision value of 84.9\n",
    "\n",
    "So, based on the above precision values, it can be concluded that the precision value is highest for the SVM poly kernel. However out of the Decision tree classifiers, we see an increase of precision score for the random search cv compared to the grid search."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
