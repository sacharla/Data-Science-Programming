{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxGJbLsUhuc8"
   },
   "source": [
    "# Week05 -\n",
    "\n",
    "In this week we look at using ensembles of models to improve the performance of our models. We will look at the following:\n",
    "\n",
    "* RandomForest\n",
    "* AdaBoost\n",
    "* Gradiant Boosting\n",
    "* XG Boosting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tuXRZKEYrDa"
   },
   "source": [
    "## Introduction and Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q08EVUytY3eh"
   },
   "source": [
    "In this notebook, we will reuse the Universal Bank dataset.\n",
    "\n",
    "This time, we are developing a model to predict whether a customer will accept a personal loan offer. The dataset contains 5000 observations and 14 variables. The data is available on one of my GitHub repos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmYLcm3aY8X5"
   },
   "source": [
    "## Install and import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to install xgboost (it's not part of the sklearn package)\n",
    "# !conda install xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8zNdljvIhuc8"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGgrXNQPZT3J"
   },
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "q3u5LsGyhudA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "3   4   35           9     100     94112       1    2.7          2         0   \n",
       "4   5   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://github.com/timcsmith/MIS536-Public/raw/master/Data/UniversalBank.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aOH_GFGZZFx"
   },
   "source": [
    "## Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "id": "OkUM_mnHhudC",
    "outputId": "b4e542fe-5d03-4602-e4d9-06a6d0e7c65d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
      "0   1   25           1      49     91107       4    1.6          1         0   \n",
      "1   2   45          19      34     90089       3    1.5          1         0   \n",
      "2   3   39          15      11     94720       1    1.0          1         0   \n",
      "3   4   35           9     100     94112       1    2.7          2         0   \n",
      "4   5   35           8      45     91330       4    1.0          2         0   \n",
      "\n",
      "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
      "0              0                   1           0       0           0  \n",
      "1              0                   1           0       0           0  \n",
      "2              0                   0           0       0           0  \n",
      "3              0                   0           0       0           0  \n",
      "4              0                   0           0       0           1  \n",
      "Index(['ID', 'Age', 'Experience', 'Income', 'ZIP Code', 'Family', 'CCAvg',\n",
      "       'Education', 'Mortgage', 'Personal Loan', 'Securities Account',\n",
      "       'CD Account', 'Online', 'CreditCard'],\n",
      "      dtype='object')\n",
      "                ID          Age   Experience       Income      ZIP Code  \\\n",
      "count  5000.000000  5000.000000  5000.000000  5000.000000   5000.000000   \n",
      "mean   2500.500000    45.338400    20.104600    73.774200  93152.503000   \n",
      "std    1443.520003    11.463166    11.467954    46.033729   2121.852197   \n",
      "min       1.000000    23.000000    -3.000000     8.000000   9307.000000   \n",
      "25%    1250.750000    35.000000    10.000000    39.000000  91911.000000   \n",
      "50%    2500.500000    45.000000    20.000000    64.000000  93437.000000   \n",
      "75%    3750.250000    55.000000    30.000000    98.000000  94608.000000   \n",
      "max    5000.000000    67.000000    43.000000   224.000000  96651.000000   \n",
      "\n",
      "            Family        CCAvg    Education     Mortgage  Personal Loan  \\\n",
      "count  5000.000000  5000.000000  5000.000000  5000.000000    5000.000000   \n",
      "mean      2.396400     1.937938     1.881000    56.498800       0.096000   \n",
      "std       1.147663     1.747659     0.839869   101.713802       0.294621   \n",
      "min       1.000000     0.000000     1.000000     0.000000       0.000000   \n",
      "25%       1.000000     0.700000     1.000000     0.000000       0.000000   \n",
      "50%       2.000000     1.500000     2.000000     0.000000       0.000000   \n",
      "75%       3.000000     2.500000     3.000000   101.000000       0.000000   \n",
      "max       4.000000    10.000000     3.000000   635.000000       1.000000   \n",
      "\n",
      "       Securities Account  CD Account       Online   CreditCard  \n",
      "count         5000.000000  5000.00000  5000.000000  5000.000000  \n",
      "mean             0.104400     0.06040     0.596800     0.294000  \n",
      "std              0.305809     0.23825     0.490589     0.455637  \n",
      "min              0.000000     0.00000     0.000000     0.000000  \n",
      "25%              0.000000     0.00000     0.000000     0.000000  \n",
      "50%              0.000000     0.00000     1.000000     0.000000  \n",
      "75%              0.000000     0.00000     1.000000     1.000000  \n",
      "max              1.000000     1.00000     1.000000     1.000000  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  5000 non-null   int64  \n",
      " 1   Age                 5000 non-null   int64  \n",
      " 2   Experience          5000 non-null   int64  \n",
      " 3   Income              5000 non-null   int64  \n",
      " 4   ZIP Code            5000 non-null   int64  \n",
      " 5   Family              5000 non-null   int64  \n",
      " 6   CCAvg               5000 non-null   float64\n",
      " 7   Education           5000 non-null   int64  \n",
      " 8   Mortgage            5000 non-null   int64  \n",
      " 9   Personal Loan       5000 non-null   int64  \n",
      " 10  Securities Account  5000 non-null   int64  \n",
      " 11  CD Account          5000 non-null   int64  \n",
      " 12  Online              5000 non-null   int64  \n",
      " 13  CreditCard          5000 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 547.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "# read the first row of the dataset \n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "print(df.describe())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiaaNFX2Zf-I"
   },
   "source": [
    "## Clean/transform data (where necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "3JuJlVGDkINJ",
    "outputId": "082781c3-db3c-44e8-a7fd-ba35f35cbbfc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Age', 'Experience', 'Income', 'ZIP Code', 'Family', 'CCAvg',\n",
       "       'Education', 'Mortgage', 'Personal Loan', 'Securities Account',\n",
       "       'CD Account', 'Online', 'CreditCard'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# based on findings from data exploration, we need to clean up colum names, as there are some leading whitespace characters\n",
    "df.columns = [s.strip() for s in df.columns] \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the columns we are not using as predictors (see previous notebooks -- we are given a subset of input variables to consider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['ID', 'ZIP Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "      <th>Edu_2</th>\n",
       "      <th>Edu_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Experience  Income  Family  CCAvg  Mortgage  Personal Loan  \\\n",
       "0   25           1      49       4    1.6         0              0   \n",
       "1   45          19      34       3    1.5         0              0   \n",
       "2   39          15      11       1    1.0         0              0   \n",
       "\n",
       "   Securities Account  CD Account  Online  CreditCard  Edu_2  Edu_3  \n",
       "0                   1           0       0           0      0      0  \n",
       "1                   1           0       0           0      0      0  \n",
       "2                   0           0       0           0      0      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# translation education categories into dummy vars\n",
    "df = df.join(pd.get_dummies(df['Education'], prefix='Edu', drop_first=True))\n",
    "df.drop('Education', axis=1, inplace = True)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKY30W1pZxCP"
   },
   "source": [
    "## Split data intro training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "d0fAfB0ThudG",
    "outputId": "47f231af-3781-4603-95b8-d9a1fca0236e"
   },
   "outputs": [],
   "source": [
    "# construct datasets for analysis\n",
    "target = 'Personal Loan'\n",
    "predictors = list(df.columns)\n",
    "predictors.remove(target)\n",
    "X = df[predictors]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "id": "t0DkCAoChudI",
    "outputId": "4f5824b6-d5e0-419c-c916-6be218916af2"
   },
   "outputs": [],
   "source": [
    "# create the training set and the test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2A_u7rQhuc_"
   },
   "source": [
    "## Prediction with Decision Tree (using default parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30gNRdX-qtNT"
   },
   "source": [
    "You can find details about SKLearm's DecisionTree classifier [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbPfUmcEXf6K"
   },
   "source": [
    "Create a decision tree using all of the default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "UZ60Vn1AhudK"
   },
   "outputs": [],
   "source": [
    "dtree=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntgxBhvJXkjp"
   },
   "source": [
    "Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "xPL4rRlVhudM",
    "outputId": "db26a1f0-23c9-4a02-87c5-34e3dbd71ccf"
   },
   "outputs": [],
   "source": [
    "_ = dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMvD4-9wXy_1"
   },
   "source": [
    "Review of the performance of the model on the validation/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "YAcO31dIX7JE",
    "outputId": "797a7c84-5c1c-4ec8-c75e-12c675ea8061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.9060402684563759\n",
      "Accuracy Score:   0.9873333333333333\n",
      "Precision Score:  0.9642857142857143\n",
      "F1 Score:         0.9342560553633219\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the recall result from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with RandomForest (using default parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all our classifiers, RandomeForestClassifier has a number of parameters that can be adjusted/tuned. In this example below, we simply accept the defaults. You may want to experiment with changing the defaul values and also use GridSearchCV to explore ranges of values.\n",
    "\n",
    "* n_estimators: The number of trees in the forsest\n",
    "    - A deeper tree might increase the performance, but also the complexity and chances to overfit.\n",
    "    - The value must be an integer greater than 0. Default is 100.  \n",
    "* max_depth: The maximum depth per tree. \n",
    "    - Deeper trees might increase the performance, but also the complexity and chances to overfit.\n",
    "    - The value must be an integer greater than 0. Default is None, which allows the tree to grow without constraint.\n",
    "* See the SciKit Learn documentation for more details. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = rforest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rforest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.8456375838926175\n",
      "Accuracy Score:   0.9833333333333333\n",
      "Precision Score:  0.984375\n",
      "F1 Score:         0.9097472924187726\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the recall result from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest_recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with randomsearchcv on RandomForest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 500 candidates, totalling 5000 fits\n",
      "The best recall score is 0.7764705882352941\n",
      "... with parameters: {'n_estimators': 5, 'min_samples_split': 17, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0001, 'max_leaf_nodes': 34, 'max_depth': 42, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 5000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.48012478 0.2540107  0.11648841 0.33493761 0.77647059 0.21818182\n",
      " 0.12620321 0.12121212 0.13939394 0.48342246 0.07771836 0.12121212\n",
      " 0.36203209 0.23270945 0.21256684 0.27067736 0.34081996 0.11515152\n",
      " 0.25757576 0.17575758 0.27272727        nan 0.15454545 0.40935829\n",
      " 0.42682709 0.05124777 0.13226381 0.19607843 0.11818182 0.03939394\n",
      " 0.21639929 0.42237077 0.26319073 0.36818182 0.09313725 0.11737968\n",
      " 0.17816399 0.61238859 0.72174688 0.23217469 0.45918004 0.61033868\n",
      " 0.18039216 0.17878788 0.15918004 0.25276292 0.48306595 0.70935829\n",
      " 0.14750446 0.1597148  0.16060606 0.         0.25606061 0.49795009\n",
      " 0.1872549  0.46827094 0.32005348 0.16568627 0.2530303  0.32308378\n",
      " 0.25757576 0.36550802 0.4587344  0.43761141 0.38065954 0.31354724\n",
      " 0.21016043 0.08404635 0.21417112 0.14420677 0.16836007 0.12691622\n",
      " 0.17745098 0.13538324 0.41345811 0.49875223 0.13903743 0.54670232\n",
      " 0.3057041  0.27156863 0.21702317 0.05757576 0.47094474 0.23520499\n",
      " 0.0815508  0.         0.50320856 0.25918004 0.21212121 0.55623886\n",
      " 0.31105169 0.23538324 0.08778966 0.27424242 0.06666667 0.33484848\n",
      " 0.15695187 0.34117647 0.01212121 0.21381462 0.49286988 0.16292335\n",
      " 0.40989305 0.43716578 0.55       0.35757576 0.20606061 0.18627451\n",
      " 0.40160428 0.45311943 0.06604278 0.03939394 0.13030303 0.18404635\n",
      " 0.13386809 0.12557932 0.06363636 0.09670232 0.18787879 0.05650624\n",
      " 0.40516934 0.11515152 0.20463458 0.39875223 0.1        0.27878788\n",
      " 0.22121212 0.01515152 0.25       0.10766488 0.06969697 0.73074866\n",
      " 0.25311943 0.54777184 0.06666667 0.15115865 0.01515152 0.56167558\n",
      " 0.24420677 0.57032086 0.10588235 0.40258467 0.05757576 0.23502674\n",
      " 0.18600713 0.37762923 0.18092692 0.21648841 0.24723708 0.19037433\n",
      " 0.22121212 0.35329768 0.22112299 0.18039216        nan 0.15142602\n",
      " 0.27379679 0.22727273 0.0754902  0.41657754 0.30472371 0.16060606\n",
      " 0.07878788 0.48092692 0.4073975  0.28030303 0.12620321 0.09090909\n",
      " 0.13636364 0.19064171 0.09393939 0.27531194 0.19393939 0.52540107\n",
      " 0.         0.54955437 0.23582888 0.10802139 0.27165775 0.1473262\n",
      " 0.19278075 0.08787879 0.14171123 0.34099822 0.29393939 0.12727273\n",
      " 0.29901961 0.28253119 0.28698752 0.18761141 0.10606061 0.6459893\n",
      " 0.3631016  0.28609626 0.22923351 0.26506239 0.29001783 0.37406417\n",
      " 0.41907308 0.19937611 0.31212121 0.50695187 0.06060606 0.36648841\n",
      " 0.3684492  0.15454545 0.28600713 0.39884135 0.11417112 0.09358289\n",
      " 0.25819964 0.11818182 0.41942959 0.18404635 0.39491979 0.14447415\n",
      " 0.24937611 0.13226381 0.22326203 0.17807487 0.30481283 0.1083779\n",
      " 0.04242424 0.2030303  0.36399287        nan 0.37959002 0.12860963\n",
      " 0.08181818 0.32121212 0.29919786 0.67941176 0.18181818 0.30819964\n",
      " 0.3627451  0.45909091 0.1030303  0.32816399 0.22067736 0.18787879\n",
      " 0.14064171        nan 0.09590018 0.45258467 0.22201426 0.10882353\n",
      " 0.1171123  0.42174688 0.23975045 0.39385027 0.20249554 0.13939394\n",
      " 0.2026738  0.14242424 0.33458111 0.61622103 0.23600713 0.15418895\n",
      " 0.29046346 0.31122995 0.20196078 0.31755793 0.29919786 0.09937611\n",
      " 0.16506239 0.15053476 0.03636364 0.22388592 0.40828877 0.16586453\n",
      " 0.06256684 0.32878788 0.29839572 0.25329768 0.64037433 0.15918004\n",
      " 0.5714795  0.14545455 0.11363636 0.41666667 0.19215686 0.11648841\n",
      " 0.41568627        nan 0.18912656 0.32326203 0.33333333 0.31185383\n",
      " 0.45864528 0.23030303 0.4131016  0.14688057 0.10606061 0.15757576\n",
      " 0.36639929 0.16497326 0.18484848 0.11122995 0.13190731 0.02121212\n",
      " 0.04545455 0.03333333 0.09010695 0.75508021 0.2030303  0.65222816\n",
      " 0.16969697 0.64358289 0.         0.03636364 0.21818182 0.13190731\n",
      " 0.41417112 0.16532977 0.33458111 0.2        0.16622103 0.39857398\n",
      " 0.34411765 0.18627451 0.13511586 0.22629234 0.31907308 0.23939394\n",
      " 0.07780749 0.06666667 0.31372549 0.17878788 0.17156863 0.30748663\n",
      " 0.21470588 0.15757576 0.15926916 0.22727273 0.73360071 0.22959002\n",
      " 0.13547237 0.23636364 0.20552585 0.44982175 0.1201426  0.2442959\n",
      " 0.12727273 0.19875223 0.27272727 0.08663102 0.26969697 0.31622103\n",
      " 0.38930481 0.06969697 0.28360071 0.05757576 0.08181818 0.13636364\n",
      " 0.16827094 0.57094474 0.09019608 0.6100713  0.56791444 0.33333333\n",
      " 0.         0.29848485 0.19875223 0.33386809 0.49509804 0.25944742\n",
      " 0.25035651 0.08484848 0.45962567 0.03030303 0.11515152 0.27843137\n",
      " 0.14456328 0.35356506 0.42540107 0.08787879 0.09393939 0.0969697\n",
      " 0.14848485 0.15641711 0.28983957 0.09875223 0.23030303 0.57040998\n",
      " 0.18404635 0.41381462 0.58538324 0.12860963 0.18012478 0.21363636\n",
      " 0.1969697  0.22352941 0.58270945 0.4114082  0.14242424 0.1745098\n",
      " 0.35454545 0.27673797 0.46221034 0.18092692 0.13030303 0.1416221\n",
      " 0.27272727 0.05454545 0.27575758 0.06363636 0.13502674 0.13636364\n",
      " 0.11782531 0.25       0.1030303  0.44073084 0.65240642 0.25249554\n",
      " 0.11417112 0.25606061 0.14393939 0.2926025  0.36506239 0.3473262\n",
      " 0.05151515 0.51657754 0.34839572 0.03030303 0.23484848 0.21381462\n",
      " 0.12727273 0.14242424 0.2040107  0.26791444 0.08787879 0.13805704\n",
      " 0.06363636 0.12067736 0.1        0.11426025 0.65846702 0.09393939\n",
      " 0.23333333 0.2969697  0.39554367 0.36194296 0.10187166 0.28903743\n",
      " 0.22932264 0.20606061 0.66461676 0.23511586 0.26024955 0.18654189\n",
      " 0.12210339 0.3385918  0.37745098 0.45008913 0.2872549  0.11729055\n",
      " 0.22655971 0.14768271 0.16363636        nan 0.12477718 0.20427807\n",
      " 0.18377897 0.36809269 0.         0.17575758 0.24545455 0.20606061\n",
      " 0.49759358 0.32727273 0.63377897 0.31399287 0.09393939 0.52326203\n",
      " 0.15008913 0.54857398 0.32914439 0.21461676 0.72745098 0.09893048\n",
      " 0.1030303  0.57950089 0.05730838 0.18181818 0.22727273 0.1412656\n",
      " 0.31818182 0.12121212 0.7184492  0.17352941 0.22121212 0.29581105\n",
      " 0.34171123 0.15454545 0.28627451 0.14438503 0.16363636 0.13939394\n",
      " 0.38244207 0.16969697]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Srinidhi\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.49075317 0.2785732  0.10350372 0.33430954 0.86468714 0.24832215\n",
      " 0.13397849 0.11610738 0.13892617 0.53539195 0.0816487  0.13355705\n",
      " 0.34380042 0.21144555 0.19688157 0.2431564  0.31455156 0.10167785\n",
      " 0.26174497 0.18993289 0.26040268        nan 0.15167785 0.41939868\n",
      " 0.43359885 0.04464556 0.14032269 0.17756197 0.14395973 0.04697987\n",
      " 0.21023885 0.44512575 0.27286173 0.35416921 0.095676   0.11816035\n",
      " 0.20573068 0.61905634 0.78516598 0.25785709 0.47296229 0.63944591\n",
      " 0.18237408 0.22416107 0.15582107 0.21424536 0.48803584 0.73483267\n",
      " 0.15307324 0.15978917 0.17114094 0.         0.27193637 0.524056\n",
      " 0.20005762 0.48065442 0.29569973 0.18633652 0.26454478 0.33667435\n",
      " 0.29261745 0.36924728 0.48639301 0.44308521 0.43534224 0.34274964\n",
      " 0.17831785 0.08023298 0.2390256  0.1671977  0.17224256 0.13859512\n",
      " 0.1692213  0.14569747 0.5039003  0.50717352 0.13997356 0.57668407\n",
      " 0.31950715 0.26818521 0.22424468 0.06744966 0.51226019 0.25140781\n",
      " 0.07452602 0.         0.51740221 0.30148916 0.23926174 0.59341627\n",
      " 0.33232097 0.25714754 0.07081328 0.26589723 0.07013423 0.33937134\n",
      " 0.1674813  0.35345174 0.02315436 0.2427632  0.49678892 0.15506406\n",
      " 0.39750864 0.43812736 0.59679457 0.37885906 0.21275168 0.17396109\n",
      " 0.43201817 0.47493616 0.06345446 0.04463087 0.12751678 0.19536077\n",
      " 0.11433914 0.13303392 0.0744989  0.10673514 0.21845638 0.05375794\n",
      " 0.42826475 0.13053691 0.18399657 0.42321538 0.11342282 0.28322148\n",
      " 0.22080537 0.02583893 0.25517366 0.10647753 0.08624161 0.76199241\n",
      " 0.25818928 0.58396154 0.08422819 0.16748808 0.02348993 0.6095824\n",
      " 0.24311007 0.56798409 0.11242967 0.41278444 0.06610738 0.24504779\n",
      " 0.19417215 0.40311617 0.17655526 0.18839175 0.2592118  0.1906221\n",
      " 0.25403814 0.33164192 0.2459901  0.16855354        nan 0.15605496\n",
      " 0.30254559 0.22885906 0.08961426 0.43672067 0.3279981  0.18120805\n",
      " 0.08624161 0.51148284 0.43672745 0.27767157 0.11415045 0.09060403\n",
      " 0.13053691 0.24334395 0.11073826 0.29031591 0.2204698  0.56464082\n",
      " 0.         0.58876121 0.2587689  0.10981289 0.26786885 0.14169435\n",
      " 0.21181615 0.08422819 0.11547014 0.32091158 0.27416107 0.12080537\n",
      " 0.32660159 0.3139708  0.30005423 0.21683389 0.11208054 0.66703839\n",
      " 0.376205   0.3072142  0.2403724  0.23835785 0.31217658 0.41893205\n",
      " 0.41093033 0.21849366 0.31610738 0.54586243 0.07348993 0.41011344\n",
      " 0.372577   0.17483786 0.29851987 0.40243599 0.10005988 0.11314826\n",
      " 0.25663006 0.13960071 0.45620975 0.18394346 0.42235103 0.13562922\n",
      " 0.23408018 0.14269541 0.24002892 0.18699749 0.32059069 0.10876438\n",
      " 0.05033557 0.2204698  0.34252254        nan 0.39652114 0.10686733\n",
      " 0.08758389 0.33758389 0.31485323 0.73548912 0.16879195 0.32387974\n",
      " 0.40206766 0.46723838 0.11175062 0.31092355 0.2382878  0.1966443\n",
      " 0.14516869        nan 0.09539579 0.46023659 0.22300635 0.08995887\n",
      " 0.1434061  0.4153289  0.24020292 0.41713782 0.23328588 0.15637584\n",
      " 0.23391521 0.1647651  0.33003299 0.64114071 0.27256005 0.15138183\n",
      " 0.31916819 0.33400221 0.16316182 0.35444377 0.30206201 0.10814069\n",
      " 0.15783111 0.1457178  0.0533557  0.23761327 0.42053194 0.17083814\n",
      " 0.06249068 0.34306488 0.32295438 0.27329108 0.70056945 0.1903724\n",
      " 0.59679231 0.15067114 0.12431474 0.47398933 0.20186428 0.13034597\n",
      " 0.45193094        nan 0.17297019 0.35782885 0.36845638 0.34163898\n",
      " 0.49450772 0.22181208 0.40285517 0.14272931 0.13861094 0.1590604\n",
      " 0.38425643 0.16521366 0.20167785 0.10877455 0.11960319 0.03724832\n",
      " 0.06006711 0.03489933 0.08932954 0.7807708  0.19530201 0.67202901\n",
      " 0.1896233  0.70186428 0.         0.03456376 0.24932886 0.15955528\n",
      " 0.44742616 0.15443247 0.34475968 0.20067114 0.16948342 0.42728177\n",
      " 0.3450783  0.19074865 0.11216302 0.22860936 0.32064041 0.26711748\n",
      " 0.08830475 0.06342282 0.30552505 0.2043692  0.1544336  0.30652046\n",
      " 0.21547353 0.17651007 0.15615213 0.25402685 0.72174542 0.21579554\n",
      " 0.12692925 0.23959732 0.18358755 0.47529885 0.11217884 0.28434343\n",
      " 0.13758389 0.20177276 0.31006711 0.10446523 0.28120805 0.31966985\n",
      " 0.41322961 0.08758389 0.30449461 0.08489933 0.08758389 0.14932886\n",
      " 0.15414661 0.62605247 0.11685309 0.63105439 0.61024676 0.33221477\n",
      " 0.         0.30790455 0.19172372 0.36973087 0.54244458 0.2645154\n",
      " 0.22424129 0.11442953 0.51083768 0.04161074 0.12214765 0.27383454\n",
      " 0.13161933 0.38900752 0.43807312 0.09127517 0.09630872 0.11979866\n",
      " 0.16778523 0.16384313 0.3430468  0.09908481 0.21879195 0.60560301\n",
      " 0.20070956 0.40983436 0.6186993  0.10451834 0.19778659 0.21589949\n",
      " 0.20536913 0.25037625 0.61164215 0.42960477 0.15872483 0.17861049\n",
      " 0.34597315 0.28977357 0.48266784 0.16584299 0.13993289 0.13866631\n",
      " 0.28557047 0.05503356 0.28489933 0.07348993 0.14906899 0.14899329\n",
      " 0.09732448 0.26154272 0.11308725 0.43805731 0.71532551 0.27169231\n",
      " 0.09400945 0.27562877 0.1357117  0.30679389 0.38874088 0.35678146\n",
      " 0.06174497 0.5179163  0.34531896 0.04060403 0.27264592 0.20652272\n",
      " 0.17986577 0.14295754 0.2116026  0.24749396 0.1        0.14508847\n",
      " 0.07685016 0.13461234 0.08557047 0.11045692 0.66732538 0.11946309\n",
      " 0.24328859 0.33959732 0.4215895  0.34311007 0.09439473 0.29782727\n",
      " 0.22591463 0.25939597 0.68612071 0.24575396 0.29266151 0.17057601\n",
      " 0.11292229 0.36149527 0.4299765  0.50617246 0.28395476 0.13795901\n",
      " 0.24803742 0.16414141 0.17885906        nan 0.14321289 0.21829255\n",
      " 0.18734436 0.37499492 0.         0.19530201 0.24295302 0.20302013\n",
      " 0.48311188 0.32516779 0.68952613 0.27993695 0.10838926 0.55947732\n",
      " 0.15886042 0.59726911 0.34068651 0.22150137 0.75430705 0.09167853\n",
      " 0.12785235 0.64253045 0.06779992 0.20100671 0.21107383 0.13265202\n",
      " 0.34295302 0.13892617 0.73483267 0.15890674 0.23456376 0.29974578\n",
      " 0.32757327 0.16174497 0.31595824 0.14937405 0.15604027 0.14463087\n",
      " 0.39252593 0.16040268]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "met_grid= 'recall'\n",
    "kfolds = 10\n",
    "\n",
    "param_grid = {\n",
    " 'n_estimators': np.arange(1, 10),\n",
    " 'criterion' :['gini', 'entropy'],\n",
    " 'max_depth': np.arange(1,50), \n",
    " 'min_samples_split': np.arange(1,50),  \n",
    " 'min_samples_leaf': np.arange(1,50),\n",
    " 'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    " 'max_leaf_nodes': np.arange(5, 50), \n",
    "             }\n",
    "\n",
    "RF = RandomForestClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = RF, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=met_grid, verbose=1, n_jobs=-1, # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {met_grid} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with ADABoost (using default parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all our classifiers, ADABoostClassifier has a number of parameters that can be adjusted/tuned. In this example below, we simply accept the defaults. You may want to experiment with changing the defaul values and also use GridSearchCV to explore ranges of values.\n",
    "\n",
    "* max_depth: The maximum depth per tree. \n",
    "    - A deeper tree might increase the performance, but also the complexity and chances to overfit.\n",
    "    - The value must be an integer greater than 0. Default is None (meaning, the tree can grow to a point where all leaves have 1 observation).\n",
    "* learning_rate: The learning rate determines the step size at each iteration while your model optimizes toward its objective. \n",
    "    - A low learning rate makes computation slower, and requires more rounds to achieve the same reduction in residual error as a model with a high learning rate. But it optimizes the chances to reach the best optimum.\n",
    "    - Larger learning rates may not converge on a solution.\n",
    "    - The value must be between 0 and 1. Default is 0.3.\n",
    "* n_estimators: The number of trees in our ensemble. \n",
    "    - Equivalent to the number of boosting rounds.\n",
    "    - The value must be an integer greater than 0. Default is 100.\n",
    "* See the SciKit Learn documentation for more details. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aboost = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = aboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = aboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.7248322147651006\n",
      "Accuracy Score:   0.9626666666666667\n",
      "Precision Score:  0.8780487804878049\n",
      "F1 Score:         0.7941176470588235\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the recall result from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "aboost_recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all our classifiers, GradientBoostingClassifier has a number of parameters that can be adjusted/tuned. In this example below, we simply accept the defaults. You may want to experiment with changing the defaul values and also use GridSearchCV to explore ranges of values.\n",
    "\n",
    "* max_depth: The maximum depth per tree. \n",
    "    - A deeper tree might increase the performance, but also the complexity and chances to overfit.\n",
    "    - The value must be an integer greater than 0. Default is None (meaning, the tree can grow to a point where all leaves have 1 observation).\n",
    "* learning_rate: The learning rate determines the step size at each iteration while your model optimizes toward its objective. \n",
    "    - A low learning rate makes computation slower, and requires more rounds to achieve the same reduction in residual error as a model with a high learning rate. But it optimizes the chances to reach the best optimum.\n",
    "    - Larger learning rates may not converge on a solution.\n",
    "    - The value must be between 0 and 1. Default is 0.3.\n",
    "* n_estimators: The number of trees in our ensemble. \n",
    "    - Equivalent to the number of boosting rounds.\n",
    "    - The value must be an integer greater than 0. Default is 100.\n",
    "* See the SciKit Learn documentation for more details. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = gboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.8657718120805369\n",
      "Accuracy Score:   0.9826666666666667\n",
      "Precision Score:  0.9555555555555556\n",
      "F1 Score:         0.9084507042253522\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the recall result from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost_recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all our classifiers, XGBoost has a number of parameters that can be adjusted/tuned. In this example below, we simply accept the defaults. You may want to experiment with changing the defaul values and also use GridSearchCV to explore ranges of values.\n",
    "\n",
    "* max_depth: The maximum depth per tree. \n",
    "    - A deeper tree might increase the performance, but also the complexity and chances to overfit.\n",
    "    - The value must be an integer greater than 0. Default is 6.\n",
    "* learning_rate: The learning rate determines the step size at each iteration while your model optimizes toward its objective. \n",
    "    - A low learning rate makes computation slower, and requires more rounds to achieve the same reduction in residual error as a model with a high learning rate. But it optimizes the chances to reach the best optimum.\n",
    "    - The value must be between 0 and 1. Default is 0.3.\n",
    "* n_estimators: The number of trees in our ensemble. \n",
    "    - Equivalent to the number of boosting rounds.\n",
    "    - The value must be an integer greater than 0. Default is 100.\n",
    "* colsample_bytree: Represents the fraction of columns to be randomly sampled for each tree. \n",
    "    - It might improve overfitting.\n",
    "    - The value must be between 0 and 1. Default is 1.\n",
    "* subsample: Represents the fraction of observations to be sampled for each tree. \n",
    "    - A lower values prevent overfitting but might lead to under-fitting.\n",
    "    - The value must be between 0 and 1. Default is 1.\n",
    "* See the XGBoost documentation for more details. https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = xgboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Model             Score       \n",
      "************************************\n",
      ">> Recall Score:  0.8926174496644296\n",
      "Accuracy Score:   0.9853333333333333\n",
      "Precision Score:  0.9568345323741008\n",
      "F1 Score:         0.9236111111111113\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Model':^18}{'Score':^18}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'>> Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the recall result from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Summarize results    \n",
    "\n",
    "As usual -- in this section you provide a recap your approach, results, and discussion of findings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall scores...\n",
      "Decision Tree:    0.9060402684563759\n",
      "Random Forest:    0.8456375838926175\n",
      "Random Forest (Random Search): 0.7764705882352941\n",
      "Ada Boosted Tree: 0.7248322147651006\n",
      "Gradient Tree:    0.8657718120805369\n",
      "XGBoost Tree:     0.8926174496644296\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall scores...\")\n",
    "print(f\"{'Decision Tree:':18}{dtree_recall}\")\n",
    "print(f\"{'Random Forest:':18}{rforest_recall}\")\n",
    "print(f\"Random Forest (Random Search): {rand_search.best_score_}\")\n",
    "print(f\"{'Ada Boosted Tree:':18}{aboost_recall}\")\n",
    "print(f\"{'Gradient Tree:':18}{gboost_recall}\")\n",
    "print(f\"{'XGBoost Tree:':18}{xgboost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and Findings:\n",
    "\n",
    "Based on the above summerized results for Recall score measures, it can be seen that for the random forest classifier, when we are to apply the Random Search CV on the model with the scoring measures, we see that the recall score is 77.64. The best performing model as per the above scores is the Decision Tree classifier. However, further improvements could be made to the Random Forest to bring up the score using Grid Search and by tuning the parameters further based on the results we have acheived from the randomsearch. I have tried doing the same and I have seen the recall score increase to 86.3. Still, we see that the Decision Tree classifier is working the best. The second best performing model based on the recall score is XGboost. However, this cannot be the final decision as the rest of the other models have default parameters set and are not tuned to predict the best parameters for the recall score. Hence it can be concluded that with the proper parameter tuning, we can increase the model performance."
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Class08b-decision_tree_tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b056086e24cb5602cbcb82122035cd3d6ee2ccbf5df29c16e348c108b0f83be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
