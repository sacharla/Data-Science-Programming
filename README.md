# Data-Science-Programming

Gives an indepth analysis of the code and weekly assignments on the data science programming course at USF. It contains weekly reports and assignment submissions that can be referred for topics related to Machine Learning, Neural Networks, Autoencoders etc. Every document can be found under the each brach based on the weeks.


Reflection:
week 1:
This has been a great week of revising on the data cleaning and preprocessing procedures. I have learned how to properly clean the data to further use it for the modeling. I have also used the Airbnb dataset to do one hot encoding and dummy encoding of the data.

week2:
I have gained exposure to various modeling techniques such as simple linear regression, polynomial regression, logistic regression by applying them on the Airbnb dataset. I have also gained knowledge on the regularization topics such as Ridge Regression, Lasso Regression, Early stopping, Elastic net, L1 and L2 etc.

week3:
I have gained knowlegde on SVM(Support vector machine) and its primary kernels: Linear kernel, RBF and polynomial kernels. I have applied SVM to different datasets and evaluated the performances based on the kernels and was also able to use the python scripting methodology to evaluate the accuracy of the predictions.

week4:
I was able to gain deeper perspective on the decision tree classifier and understood the concepts such as variance, entropy, gini index and biases. I have also learned the hyperparameter tuning techniques to figure out the best parameters and to optmizie the performance of the model.

week5:
Here I have acquired further knowledge on the Ensemble techniques such as Bagging and boosting covering the concepts such AdaBoost, XGBoost and Random Forest. I have been exposed to the Exhaustive searching methods for the trained data such as Random Search CV and the Grid Search CV.

week6:
During this week, I have learned about the Text Mining of the data where I have leart various text mining techniques such as Lemmatization, Tokenization, Term Frequencey- Inverse Document Frequency (TF-IDF) and also on how to reduce the number of tokens of the data being generated such as stemming, Lemmanization,eliminating stopwords, correcting misspelled tokens and the parts of speeh tagging.

week7:
During this week, I have studied about the Neural Networks and I have learnt about perceptrons and the artificial neural networks. I have used this knowledge to work on the datasets to build complex neural netowrk using MLP classifier. I have used a handwritten digits dataset and applied hyperparameter tuning and the regularization techniques to gain deeper understanding on the importance of using the NNs for the digit recognition problems.

week8:
I was introduced to the Deep Neural Networks this week where I was able to learn popular frameworks such as keras and tensorflow.

week9:
I was introduced to the Convolution Neural Networks this week and I have used the keras and the tensorflow libraries to apply the CNN for the image detection.

week10:
I have gained basic knowledge on Recurrent Neural Netowkrs (RNNs) and the application of the time series and the sequential analysis. I have used the LYFT dataset for the 100 days to divide the data into 10 days and to predict the 10th day stock price using the previous 9 days prices. I have used Simple RNN, LSTM and the Conv1d models to predict the stock prices.

week11:
During this week, I was introduced to the autoendcoder concept and have learnt about the fundamentals of autoencoders and their ability to recontruct an image. I have used the MNIST dataset and added a new image of the randomly generated digits and the first letter of my first name. The recognition was successful and was able to reconstruct the image. This proved the autoencoders ability to reduce the difference between the input data and the output data.
